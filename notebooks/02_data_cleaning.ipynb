{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b45791-2cb6-4d38-8bcf-07438e9eec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ XO Project - Data Cleaning Phase\n",
      "============================================================\n",
      "Objective: Clean and prepare exoplanet data for habitability analysis\n",
      "============================================================\n",
      "Found header at line 97\n",
      "Raw dataset loaded: 38,779 planets, 92 features\n",
      "Memory usage: 68.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 - Setup and Data Loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üßπ XO Project - Data Cleaning Phase\")\n",
    "print(\"=\"*60)\n",
    "print(\"Objective: Clean and prepare exoplanet data for habitability analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load the raw data (using knowledge from notebook 01)\n",
    "with open('../data/raw/exoplanet_data.csv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Find header line containing actual column names\n",
    "header_line_index = None\n",
    "for i, line in enumerate(lines):\n",
    "    if 'pl_name' in line and not line.strip().startswith('#'):\n",
    "        header_line_index = i\n",
    "        print(f\"Found header at line {i + 1}\")\n",
    "        break\n",
    "\n",
    "# Load data starting from header\n",
    "df_raw = pd.read_csv('../data/raw/exoplanet_data.csv',\n",
    "                     skiprows=header_line_index,\n",
    "                     sep=',',\n",
    "                     on_bad_lines='skip',\n",
    "                     low_memory=False)\n",
    "\n",
    "print(f\"Raw dataset loaded: {df_raw.shape[0]:,} planets, {df_raw.shape[1]} features\")\n",
    "print(f\"Memory usage: {df_raw.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281486f6-d212-4778-8209-e75a79466970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Quality Assessment:\n",
      "==================================================\n",
      "‚úì pl_name      | Planet Name                         | 100.0% (38,779)\n",
      "‚úì hostname     | Host Star Name                      | 100.0% (38,779)\n",
      "‚úì pl_rade      | Planet Radius (Earth radii)         |  69.1% (26,789)\n",
      "‚úì pl_bmasse    | Planet Mass (Earth masses)          |  17.5% (6,768)\n",
      "‚úì pl_orbsmax   | Orbital Distance (AU)               |  56.2% (21,779)\n",
      "‚úì st_teff      | Stellar Temperature (K)             |  91.4% (35,435)\n",
      "‚úì st_mass      | Stellar Mass (Solar masses)         |  84.6% (32,797)\n",
      "‚úì pl_eqt       | Equilibrium Temperature (K)         |  43.7% (16,951)\n",
      "‚úì discoverymethod | Discovery Method                    | 100.0% (38,779)\n",
      "‚úì disc_year    | Discovery Year                      | 100.0% (38,779)\n",
      "\n",
      "Planets with minimum required data: 18,274 (47.1%)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 - Data Quality Assessment\n",
    "print(\"\\nData Quality Assessment:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define core habitability features based on our exploration\n",
    "core_features = {\n",
    "    'pl_name': 'Planet Name',\n",
    "    'hostname': 'Host Star Name',\n",
    "    'pl_rade': 'Planet Radius (Earth radii)',\n",
    "    'pl_bmasse': 'Planet Mass (Earth masses)',\n",
    "    'pl_orbsmax': 'Orbital Distance (AU)',\n",
    "    'st_teff': 'Stellar Temperature (K)',\n",
    "    'st_mass': 'Stellar Mass (Solar masses)',\n",
    "    'pl_eqt': 'Equilibrium Temperature (K)',\n",
    "    'discoverymethod': 'Discovery Method',\n",
    "    'disc_year': 'Discovery Year'\n",
    "}\n",
    "\n",
    "# Check availability and completeness\n",
    "available_features = {}\n",
    "for feature, description in core_features.items():\n",
    "    if feature in df_raw.columns:\n",
    "        non_null = df_raw[feature].count()\n",
    "        total = len(df_raw)\n",
    "        completeness = (non_null / total) * 100\n",
    "        available_features[feature] = completeness\n",
    "        print(f\"‚úì {feature:12} | {description:35} | {completeness:5.1f}% ({non_null:,})\")\n",
    "    else:\n",
    "        print(f\"‚úó {feature:12} | {description:35} | Not found\")\n",
    "\n",
    "# Identify minimum viable dataset\n",
    "min_required = ['pl_name', 'pl_rade', 'pl_orbsmax', 'st_teff']\n",
    "viable_subset = df_raw.dropna(subset=min_required)\n",
    "print(f\"\\nPlanets with minimum required data: {len(viable_subset):,} ({len(viable_subset)/len(df_raw)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7fea6bd-131f-41a0-a9b8-93f719f57f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outlier Detection:\n",
      "========================================\n",
      "pl_rade      | Range:     0.27 -  4282.98\n",
      "             | Outliers: 86 (0.3%)\n",
      "             | Extreme high values detected\n",
      "pl_bmasse    | Range:     0.01 - 25426.40\n",
      "             | Outliers: 180 (2.7%)\n",
      "             | Extreme high values detected\n",
      "pl_orbsmax   | Range:     0.00 - 19000.00\n",
      "             | Outliers: 14 (0.1%)\n",
      "             | Extreme high values detected\n",
      "st_teff      | Range:   415.00 - 57000.00\n",
      "             | Outliers: 5 (0.0%)\n",
      "             | Extreme high values detected\n",
      "st_mass      | Range:     0.00 -    23.56\n",
      "             | Outliers: 58 (0.2%)\n",
      "pl_eqt       | Range:    34.00 -  4050.00\n",
      "             | Outliers: 23 (0.1%)\n",
      "             | Extreme high values detected\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 - Outlier Detection and Analysis\n",
    "print(\"\\nOutlier Detection:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Define physically reasonable ranges based on known astronomy\n",
    "physical_limits = {\n",
    "    'pl_rade': (0.1, 30),        # From smallest known to largest gas giants\n",
    "    'pl_bmasse': (0.01, 5000),   # From small asteroids to brown dwarfs  \n",
    "    'pl_orbsmax': (0.001, 1000), # Very close hot Jupiters to wide binaries\n",
    "    'st_teff': (1000, 50000),    # From cool brown dwarfs to hot O stars\n",
    "    'st_mass': (0.08, 100),      # From minimum star mass to massive stars\n",
    "    'pl_eqt': (1, 3000)          # From very cold to very hot planets\n",
    "}\n",
    "\n",
    "# Analyze outliers for each feature\n",
    "outlier_summary = {}\n",
    "for feature, (min_val, max_val) in physical_limits.items():\n",
    "    if feature in df_raw.columns:\n",
    "        data = df_raw[feature].dropna()\n",
    "        outliers_low = (data < min_val).sum()\n",
    "        outliers_high = (data > max_val).sum()\n",
    "        total_outliers = outliers_low + outliers_high\n",
    "        outlier_summary[feature] = {\n",
    "            'total_outliers': total_outliers,\n",
    "            'percent': (total_outliers / len(data)) * 100,\n",
    "            'too_low': outliers_low,\n",
    "            'too_high': outliers_high,\n",
    "            'actual_range': (data.min(), data.max())\n",
    "        }\n",
    "        \n",
    "        print(f\"{feature:12} | Range: {data.min():8.2f} - {data.max():8.2f}\")\n",
    "        print(f\"             | Outliers: {total_outliers:,} ({outlier_summary[feature]['percent']:.1f}%)\")\n",
    "        if outliers_high > 0:\n",
    "            print(f\"             | Extreme high values detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73699e1b-e1c1-4f6f-a86b-777ab9124c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Implementing Data Cleaning:\n",
      "========================================\n",
      "Starting with: 38,779 planets\n",
      "Removed 86 planets with unrealistic pl_rade\n",
      "Removed 178 planets with unrealistic pl_bmasse\n",
      "Removed 10 planets with unrealistic pl_orbsmax\n",
      "Removed 4 planets with unrealistic st_teff\n",
      "Removed 45 planets with unrealistic st_mass\n",
      "Removed 20 planets with unrealistic pl_eqt\n",
      "After outlier removal: 38,436 planets\n",
      "Removed 32,541 duplicate planets\n",
      "Focused dataset: 5,895 planets, 15 features\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 - Data Cleaning Implementation\n",
    "print(\"\\nImplementing Data Cleaning:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Start with a copy for cleaning\n",
    "df_clean = df_raw.copy()\n",
    "print(f\"Starting with: {len(df_clean):,} planets\")\n",
    "\n",
    "# Step 1: Remove extreme outliers using physical limits\n",
    "cleaning_log = []\n",
    "for feature, (min_val, max_val) in physical_limits.items():\n",
    "    if feature in df_clean.columns:\n",
    "        before_count = len(df_clean)\n",
    "        \n",
    "        # Remove outliers\n",
    "        df_clean = df_clean[\n",
    "            (df_clean[feature].isna()) |  # Keep NaN values\n",
    "            ((df_clean[feature] >= min_val) & (df_clean[feature] <= max_val))\n",
    "        ]\n",
    "        \n",
    "        removed = before_count - len(df_clean)\n",
    "        if removed > 0:\n",
    "            cleaning_log.append(f\"Removed {removed:,} planets with unrealistic {feature}\")\n",
    "            print(f\"Removed {removed:,} planets with unrealistic {feature}\")\n",
    "\n",
    "print(f\"After outlier removal: {len(df_clean):,} planets\")\n",
    "\n",
    "# Step 2: Remove duplicate planet names (keep most recent data)\n",
    "before_dedup = len(df_clean)\n",
    "df_clean = df_clean.sort_values('rowupdate', ascending=False).drop_duplicates(subset=['pl_name'], keep='first')\n",
    "duplicates_removed = before_dedup - len(df_clean)\n",
    "if duplicates_removed > 0:\n",
    "    cleaning_log.append(f\"Removed {duplicates_removed:,} duplicate planets\")\n",
    "    print(f\"Removed {duplicates_removed:,} duplicate planets\")\n",
    "\n",
    "# Step 3: Create a focused dataset with core features\n",
    "core_columns = [col for col in core_features.keys() if col in df_clean.columns]\n",
    "additional_useful = ['pl_orbper', 'pl_orbeccen', 'st_rad', 'st_logg', 'pl_insol']\n",
    "useful_columns = core_columns + [col for col in additional_useful if col in df_clean.columns]\n",
    "\n",
    "df_focused = df_clean[useful_columns].copy()\n",
    "print(f\"Focused dataset: {len(df_focused):,} planets, {len(df_focused.columns)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd17b6c2-f0b5-4e4e-9de9-bc0af8ee03ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Data Analysis:\n",
      "========================================\n",
      "Missing data summary for focused dataset:\n",
      "pl_eqt          |  4,641 missing ( 78.7%) |  1,254 available\n",
      "pl_orbeccen     |  4,349 missing ( 73.8%) |  1,546 available\n",
      "pl_bmasse       |  4,001 missing ( 67.9%) |  1,894 available\n",
      "pl_insol        |  3,633 missing ( 61.6%) |  2,262 available\n",
      "pl_orbsmax      |  2,808 missing ( 47.6%) |  3,087 available\n",
      "pl_rade         |  2,738 missing ( 46.4%) |  3,157 available\n",
      "st_logg         |  2,599 missing ( 44.1%) |  3,296 available\n",
      "st_mass         |  1,203 missing ( 20.4%) |  4,692 available\n",
      "st_teff         |  1,014 missing ( 17.2%) |  4,881 available\n",
      "st_rad          |    978 missing ( 16.6%) |  4,917 available\n",
      "pl_orbper       |    296 missing (  5.0%) |  5,599 available\n",
      "pl_name         |      0 missing (  0.0%) |  5,895 available\n",
      "hostname        |      0 missing (  0.0%) |  5,895 available\n",
      "disc_year       |      0 missing (  0.0%) |  5,895 available\n",
      "discoverymethod |      0 missing (  0.0%) |  5,895 available\n",
      "\n",
      "Dataset options:\n",
      "minimal    |  1,732 planets | Features required: 15\n",
      "standard   |  1,729 planets | Features required: 15\n",
      "complete   |    252 planets | Features required: 15\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - Missing Data Strategy\n",
    "print(\"\\nMissing Data Analysis:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Calculate missing data percentages for focused dataset\n",
    "missing_analysis = pd.DataFrame({\n",
    "    'feature': df_focused.columns,\n",
    "    'missing_count': df_focused.isnull().sum(),\n",
    "    'missing_percent': (df_focused.isnull().sum() / len(df_focused) * 100).round(1),\n",
    "    'available_count': df_focused.count()\n",
    "})\n",
    "missing_analysis = missing_analysis.sort_values('missing_percent', ascending=False)\n",
    "\n",
    "print(\"Missing data summary for focused dataset:\")\n",
    "for _, row in missing_analysis.iterrows():\n",
    "    print(f\"{row['feature']:15} | {row['missing_count']:6,} missing ({row['missing_percent']:5.1f}%) | {row['available_count']:6,} available\")\n",
    "\n",
    "# Create different datasets based on completeness requirements\n",
    "datasets = {}\n",
    "\n",
    "# Dataset 1: Minimal requirements (for maximum sample size)\n",
    "min_cols = ['pl_name', 'hostname', 'pl_rade', 'pl_orbsmax', 'st_teff']\n",
    "datasets['minimal'] = df_focused.dropna(subset=min_cols)\n",
    "\n",
    "# Dataset 2: Standard requirements (good balance)\n",
    "standard_cols = min_cols + ['st_mass']\n",
    "datasets['standard'] = df_focused.dropna(subset=standard_cols)\n",
    "\n",
    "# Dataset 3: Complete requirements (for highest quality analysis)\n",
    "complete_cols = standard_cols + ['pl_bmasse', 'pl_eqt']\n",
    "datasets['complete'] = df_focused.dropna(subset=complete_cols)\n",
    "\n",
    "print(f\"\\nDataset options:\")\n",
    "for name, dataset in datasets.items():\n",
    "    print(f\"{name:10} | {len(dataset):6,} planets | Features required: {len(dataset.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ad7fcb-7b08-4f51-a084-76a74d04c610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Validation:\n",
      "==============================\n",
      "‚úÖ Planet radius should be positive: All values valid\n",
      "‚úÖ Orbital distance should be positive: All values valid\n",
      "‚úÖ Stellar temperature should be realistic: All values valid\n",
      "‚úÖ Stellar mass should be positive: All values valid\n",
      "\n",
      "Final dataset statistics:\n",
      "        pl_rade  pl_bmasse  pl_orbsmax    st_teff   st_mass    pl_eqt  \\\n",
      "count  1729.000    302.000    1729.000   1729.000  1729.000   368.000   \n",
      "mean      3.451    292.222       0.301   5520.984     0.962   975.853   \n",
      "std       3.652    613.641       4.386   1001.348     0.221   482.944   \n",
      "min       0.276      0.290       0.006   2566.000     0.090   183.000   \n",
      "25%       1.494      8.055       0.052   5191.000     0.841   598.778   \n",
      "50%       2.290     54.515       0.087   5641.000     0.956   878.500   \n",
      "75%       3.108    293.118       0.159   5910.000     1.084  1309.250   \n",
      "max      24.437   4417.837     156.000  27730.000     1.960  2594.300   \n",
      "\n",
      "       disc_year  pl_orbper  pl_orbeccen    st_rad  st_logg  pl_insol  \n",
      "count   1729.000   1727.000      312.000  1729.000  399.000  1464.000  \n",
      "mean    2016.557     55.681        0.125     1.100    4.471   371.246  \n",
      "std        3.486   1052.236        0.164     0.441    0.284   742.658  \n",
      "min     2004.000      0.240        0.000     0.119    3.276     0.100  \n",
      "25%     2014.000      4.545        0.000     0.801    4.300    29.877  \n",
      "50%     2016.000      9.767        0.065     0.993    4.490   112.100  \n",
      "75%     2018.000     23.531        0.180     1.340    4.623   384.250  \n",
      "max     2025.000  43500.000        0.941     4.140    5.520  8385.900  \n",
      "\n",
      "Cleaning Summary:\n",
      "Original dataset: 38,779 planets\n",
      "Final dataset: 1,729 planets (4.5% retained)\n",
      "Features: 15\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 - Data Validation and Final Checks\n",
    "print(\"\\nData Validation:\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Use the standard dataset for our main analysis\n",
    "df_final = datasets['standard'].copy()\n",
    "\n",
    "# Validate data ranges make sense\n",
    "validation_checks = {\n",
    "    'pl_rade': \"Planet radius should be positive\",\n",
    "    'pl_orbsmax': \"Orbital distance should be positive\", \n",
    "    'st_teff': \"Stellar temperature should be realistic\",\n",
    "    'st_mass': \"Stellar mass should be positive\"\n",
    "}\n",
    "\n",
    "validation_passed = True\n",
    "for col, description in validation_checks.items():\n",
    "    if col in df_final.columns:\n",
    "        invalid = (df_final[col] <= 0).sum()\n",
    "        if invalid > 0:\n",
    "            print(f\"‚ùå {description}: {invalid} invalid values found\")\n",
    "            validation_passed = False\n",
    "        else:\n",
    "            print(f\"‚úÖ {description}: All values valid\")\n",
    "\n",
    "# Check for reasonable value distributions\n",
    "print(f\"\\nFinal dataset statistics:\")\n",
    "numeric_cols = df_final.select_dtypes(include=[np.number]).columns\n",
    "stats_summary = df_final[numeric_cols].describe()\n",
    "print(stats_summary.round(3))\n",
    "\n",
    "print(f\"\\nCleaning Summary:\")\n",
    "print(f\"Original dataset: {len(df_raw):,} planets\")\n",
    "print(f\"Final dataset: {len(df_final):,} planets ({len(df_final)/len(df_raw)*100:.1f}% retained)\")\n",
    "print(f\"Features: {len(df_final.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34b67387-9b2a-4a9d-9b45-4d6130ac4ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving Cleaned Data:\n",
      "==============================\n",
      "Saved cleaned dataset to: ../data/processed/cleaned_data.csv\n",
      "Saved cleaning log to: ../data/processed/cleaning_log.txt\n",
      "\n",
      "Final cleaned dataset preview:\n",
      "          pl_name hostname  pl_rade  pl_bmasse  pl_orbsmax  st_teff  st_mass  \\\n",
      "37029   TOI-880 c  TOI-880    4.950        NaN     0.06350   5050.0     0.87   \n",
      "37031  TOI-880.02  TOI-880    2.190        NaN     0.03490   5050.0     0.87   \n",
      "38289   WASP-69 b  WASP-69   11.210      82.58     0.04530   4792.0     0.83   \n",
      "4786     K2-233 b   K2-233    1.315       2.40     0.03293   4796.0     0.79   \n",
      "4788     K2-233 c   K2-233    1.272       4.60     0.06640   4796.0     0.79   \n",
      "\n",
      "       pl_eqt discoverymethod  disc_year  pl_orbper  pl_orbeccen  st_rad  \\\n",
      "37029   805.0         Transit       2025   6.387270          NaN   0.830   \n",
      "37031  1085.0         Transit       2024   2.575710          NaN   0.830   \n",
      "38289   971.0         Transit       2014   3.868139          0.0   0.801   \n",
      "4786   1127.0         Transit       2018   2.467583          0.0   0.710   \n",
      "4788    794.0         Transit       2018   7.060240          0.0   0.710   \n",
      "\n",
      "       st_logg  pl_insol  \n",
      "37029     4.53       NaN  \n",
      "37031     4.53       NaN  \n",
      "38289     4.57       NaN  \n",
      "4786      4.53     269.0  \n",
      "4788      4.53      66.2  \n",
      "\n",
      "Dataset ready for feature engineering phase!\n",
      "Proceed to: 03_feature_engineering.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 - Save Cleaned Dataset\n",
    "print(\"\\nSaving Cleaned Data:\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "output_path = '../data/processed/cleaned_data.csv'\n",
    "df_final.to_csv(output_path, index=False)\n",
    "print(f\"Saved cleaned dataset to: {output_path}\")\n",
    "\n",
    "# Save cleaning log\n",
    "log_path = '../data/processed/cleaning_log.txt'\n",
    "with open(log_path, 'w') as f:\n",
    "    f.write(\"XO Project - Data Cleaning Log\\n\")\n",
    "    f.write(\"=\"*40 + \"\\n\\n\")\n",
    "    f.write(f\"Original dataset: {len(df_raw):,} planets\\n\")\n",
    "    f.write(f\"Final dataset: {len(df_final):,} planets\\n\")\n",
    "    f.write(f\"Retention rate: {len(df_final)/len(df_raw)*100:.1f}%\\n\\n\")\n",
    "    f.write(\"Cleaning steps performed:\\n\")\n",
    "    for step in cleaning_log:\n",
    "        f.write(f\"- {step}\\n\")\n",
    "\n",
    "print(f\"Saved cleaning log to: {log_path}\")\n",
    "\n",
    "# Display final dataset preview\n",
    "print(f\"\\nFinal cleaned dataset preview:\")\n",
    "print(df_final.head())\n",
    "\n",
    "print(f\"\\nDataset ready for feature engineering phase!\")\n",
    "print(f\"Proceed to: 03_feature_engineering.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab16e8f-e8d1-4b54-ab61-6a9153136f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
